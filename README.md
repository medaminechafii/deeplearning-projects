# deeplearning-projects
This repository is about my journey to learn deep learning 

1. Perceptron:
I tried to code a perceptron from scratch after reading a paper about perceptrons. The loss function in use is the logloss function, and using normal gradient descent with an arbitrary learning rate.
2. ANN:
The ANN was more of an extension on the perceptron and creating a deep neural network to fit it to data that is not linear. The loss function and gradient descent are the same in the perceptron.
